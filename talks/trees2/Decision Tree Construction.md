---
id: "85f08bf0-499e-43aa-8a6a-f9966c8b3458"
origin: "local"
---
### Decision Tree Construction


https://klrpdx.github.io/talks/trees2/images/apptree.png

https://klrpdx.github.io/talks/trees2/images/infogain.png

https://klrpdx.github.io/talks/trees2/images/dice.jpg

https://klrpdx.github.io/talks/trees2/images/die.jpg

https://klrpdx.github.io/talks/trees2/images/die.jpg
1/6 

https://klrpdx.github.io/talks/trees2/images/die.jpg
1/6 + 1/6 + 1/6 

https://klrpdx.github.io/talks/trees2/images/die.jpg
1/6 + 1/6 + 1/6 = 3/6 = 1/2 = 0.5 Probability

https://klrpdx.github.io/talks/trees2/images/die.jpg
1/6 

https://klrpdx.github.io/talks/trees2/images/die.jpg
1/6 * 1/6

https://klrpdx.github.io/talks/trees2/images/die.jpg
1/6 x 1/6 x 1/6 = 1/216 = .0046 probability

https://klrpdx.github.io/talks/trees2/images/entropy.png

https://klrpdx.github.io/talks/trees2/images/prob1.png

https://klrpdx.github.io/talks/trees2/images/prob2.png

https://klrpdx.github.io/talks/trees2/images/prob3.png

https://klrpdx.github.io//talks/trees2/images/entropynums.png

### 1.0 x 1.0 x 1.0 x 1.0  = 1.0
### 0.75 x 0.75 x 0.75 x 0.25 = 0.105
### 0.50 x 0.50 x 0.50 x 0.50 = 0.0625

## log(abc) = log(a) + log(b) + log(c)

### log(1) + log(1) + log(1) + log(1)  = 0 + 0 + 0 + 0 = 0

### log(.75) + log(.75) + log(.75) + log(.25) = -3.245

### log(.5) + log(.5) + log(.5) + log(.5) = -4

https://klrpdx.github.io/talks/trees2/images/log.png

### Information Gain = Change in Entropy

https://klrpdx.github.io/talks/trees2/images/infogain.png

https://klrpdx.github.io/talks/trees2/images/entropy_text.png

https://klrpdx.github.io/talks/trees2/images/entropy_split1.png

https://klrpdx.github.io/talks/trees2/images/entropy_split2.png

https://klrpdx.github.io/talks/trees2/images/entropy_splt3.png
